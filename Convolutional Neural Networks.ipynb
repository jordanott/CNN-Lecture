{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ImageNet](Images/imagenet.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if we use this for images? (hint: dimensions)\n",
    "![Deep](Images/deep.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurological Origins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Cat](Images/cat.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hubel and Wiesel. Receptive fields of single neurons in the cat's striate cortex. 1959\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Developed by Yann LeCun (1989)\n",
    "* Goal was to build automatic mail-sorting machines\n",
    "* First \"real-world\" application of Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/cnn.jpg)  \n",
    "* Weights are shared across space\n",
    "* Provides basis for translational invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Convolution](Images/convolution.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Algorithm](Images/alg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Time Complexity](Images/time.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run-time complexity of the convolutional operation is described by the above equation. Where $F_{n}$ is the number of filters, $H$ is the height of the input image, $W$ is the width of the image, $f_{h}$ is the height of the filter, $f_{w}$ is the width of the filter, and $f_{d}$ is the depth of the filter. It is important to note that the equation only describes the forward pass in a convolutional layer. **Backpropogation through the network is roughly twice as costly as the forward pass. This is because we must compute the loss with respect to the weights and the loss with respect to the inputs.** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Matrix](Images/conv_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectified Linear Unit (ReLU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ReLU](Images/relu.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Very inexpensive\n",
    "* Avoid vanishing gradient\n",
    "* Differentiable at all points except 0\n",
    "* Can kill neurons (Leaky ReLU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Leaky ReLU](Images/leakyrelu.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Pooling](Images/pooling.png)\n",
    "* Gives small amount of translational invariance at each level\n",
    "    * Location information of most active neuron is thrown away\n",
    "* Reduces number of inputs to next layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward-pass of a 3-layer neural network:\n",
    "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmoid)\n",
    "x = np.random.randn(3, 1) # random input vector of three numbers (3x1)\n",
    "h1 = f(np.dot(W1, x) + b1) # calculate first hidden layer activations (4x1)\n",
    "h2 = f(np.dot(W2, h1) + b2) # calculate second hidden layer activations (4x1)\n",
    "out = np.dot(W3, h2) + b3 # output neuron (1x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_{i} = \\dfrac{e^{z_{i}}}{\\sum_{j=1}^{N}e^{z_{j}}}$$\n",
    "* Output sums to one\n",
    "* Represent probability distribution across discrete mutually exclusive alternatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Softmax Derivative](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial y_{i}}{\\partial z_{i}} = y_{i}(1-y_{i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_derivative(y):\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy Cost Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C = - \\sum_{j} t_{j} \\log y_{j}$$\n",
    "\n",
    "* Very large gradient when the target value is 1 and the output is 0\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial z_{i}} = \\sum_{j} \\frac{\\partial C}{\\partial y_{i}} \\frac{\\partial y_{i}}{\\partial z_{i}} = y_{i} - t_{i} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(y,t):\n",
    "    # y: predicted, t: target\n",
    "    return y - t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dropout](Images/dropout.png)\n",
    "\n",
    "* Combat overfitting\n",
    "* Randomly drop connections during training\n",
    "* Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding CNN's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Weight Visualization](https://www.youtube.com/watch?v=AgkfIQ4IGaM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Conv1](Images/conv1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Conv3](Images/conv3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Conv5](Images/conv5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Class Activation Mapping](http://cnnlocalization.csail.mit.edu/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Code](Images/code.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TensorFlow](https://www.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Open source software library for numerical computation using data flow graphs\n",
    "* Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors)\n",
    "* Allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API\n",
    "* Originally developed by researchers and engineers working on the Google Brain Team\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Keras](https://keras.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* High level API\n",
    "* Able to use different libraries as backend\n",
    "    * TensorFlow, Theano, CNTK (Microsoft)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST](Images/mnist.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (60000, 28, 28, 1))\n",
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 96s - loss: 0.3352 - acc: 0.8978 - val_loss: 0.0764 - val_acc: 0.9757\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 95s - loss: 0.1092 - acc: 0.9679 - val_loss: 0.0506 - val_acc: 0.9834\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 95s - loss: 0.0809 - acc: 0.9757 - val_loss: 0.0420 - val_acc: 0.9861\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 96s - loss: 0.0693 - acc: 0.9803 - val_loss: 0.0396 - val_acc: 0.9868\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 95s - loss: 0.0607 - acc: 0.9818 - val_loss: 0.0339 - val_acc: 0.9886\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 94s - loss: 0.0535 - acc: 0.9842 - val_loss: 0.0326 - val_acc: 0.9890\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 100s - loss: 0.0486 - acc: 0.9854 - val_loss: 0.0306 - val_acc: 0.9892\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 96s - loss: 0.0466 - acc: 0.9861 - val_loss: 0.0307 - val_acc: 0.9894\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 94s - loss: 0.0445 - acc: 0.9867 - val_loss: 0.0293 - val_acc: 0.9902\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 97s - loss: 0.0394 - acc: 0.9880 - val_loss: 0.0303 - val_acc: 0.9907\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 93s - loss: 0.0388 - acc: 0.9884 - val_loss: 0.0308 - val_acc: 0.9899\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 96s - loss: 0.0373 - acc: 0.9888 - val_loss: 0.0276 - val_acc: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f869ddfa7d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.027582556404452771)\n",
      "('Test accuracy:', 0.99080000000000001)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Transfer Learning](Images/transfer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (300,300,3)\n",
    "input_tensor = Input(shape=input_shape)\n",
    "base_model = VGG16(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#x = Dense(1024, activation='relu')(x)\n",
    "# output layer with 'num_classes' number of catergories\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions to install CUDA 8.0, CuDNN, TensorFlow, and Keras can be found [here](https://github.com/jordanott/Useful-Things/blob/master/CUDA.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Stanford CS 231n](http://cs231n.github.io/convolutional-networks/)  \n",
    "[Keras](https://keras.io/)  \n",
    "[Keras Tutorials](https://github.com/keras-team/keras/tree/master/examples)  \n",
    "[TensorFlow](https://www.tensorflow.org/)  \n",
    "[Deep Visualization Toolbox](https://www.youtube.com/watch?v=AgkfIQ4IGaM)  \n",
    "[Transfer Learning using Keras](https://towardsdatascience.com/transfer-learning-using-keras-d804b2e04ef8)  \n",
    "[Dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
